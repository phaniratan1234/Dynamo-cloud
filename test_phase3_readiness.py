"""
Test Phase 3 Readiness for GPU Deployment
Comprehensive verification that Phase 3 will work correctly on Google Colab T4 GPU.
"""

import os
import torch
import traceback
from pathlib import Path

def test_phase3_readiness():
    """Test all Phase 3 components for GPU deployment readiness."""
    
    print("üß™ DYNAMO Phase 3 Readiness Test")
    print("=" * 60)
    
    all_tests_passed = True
    
    # Test 1: Checkpoint validation
    print("\nüîç Test 1: Checkpoint Validation")
    try:
        from utils.checkpoint_utils import validate_checkpoint_transition
        
        checkpoint_dir = "checkpoints"
        phase3_ready = validate_checkpoint_transition(2, 3, checkpoint_dir)
        
        if phase3_ready:
            print("‚úÖ Phase 3 validation passed")
        else:
            print("‚ùå Phase 3 validation failed")
            all_tests_passed = False
            
    except Exception as e:
        print(f"‚ùå Checkpoint validation error: {e}")
        all_tests_passed = False
    
    # Test 2: Phase 2 checkpoint existence and loading
    print("\nüìÇ Test 2: Phase 2 Checkpoint Loading")
    try:
        phase2_dir = Path("checkpoints/phase2")
        required_files = ["phase2_model.pt", "best_router.pt", "training_metrics.pt"]
        
        missing_files = []
        for file in required_files:
            file_path = phase2_dir / file
            if not file_path.exists():
                missing_files.append(file)
            else:
                # Test loading the checkpoint
                checkpoint = torch.load(file_path, map_location='cpu')
                print(f"‚úÖ {file} - Size: {file_path.stat().st_size / (1024*1024):.1f}MB")
        
        if missing_files:
            print(f"‚ùå Missing Phase 2 files: {missing_files}")
            all_tests_passed = False
        else:
            print("‚úÖ All Phase 2 checkpoints available and loadable")
            
    except Exception as e:
        print(f"‚ùå Phase 2 checkpoint loading error: {e}")
        all_tests_passed = False
    
    # Test 3: Model initialization and Phase 2 loading
    print("\nüèóÔ∏è Test 3: Model Initialization with Phase 2 Loading")
    try:
        from train_optimized import load_optimized_config
        from model import DynamoModel
        
        config_dict, config = load_optimized_config("config.yaml")
        model = DynamoModel(config_dict)
        
        # Test loading Phase 2 checkpoint
        phase2_checkpoint = torch.load("checkpoints/phase2/phase2_model.pt", map_location='cpu')
        model.load_state_dict(phase2_checkpoint['model_state_dict'], strict=False)
        
        # Set to Phase 3 mode
        model.set_training_phase("phase3")
        
        print("‚úÖ Model initialized and Phase 2 checkpoint loaded successfully")
        print(f"   - Total parameters: {sum(p.numel() for p in model.parameters()):,}")
        print(f"   - Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
        
    except Exception as e:
        print(f"‚ùå Model initialization error: {e}")
        traceback.print_exc()
        all_tests_passed = False
    
    # Test 4: Phase 3 trainer initialization
    print("\nüéØ Test 4: Phase 3 Trainer Initialization")
    try:
        from training.phase3_joint_finetuning import Phase3Trainer
        
        # Force CPU mode for testing (expected to fail on non-CUDA systems)
        config.device = 'cpu'
        
        trainer = Phase3Trainer(config, model)
        
        print("‚úÖ Phase 3 trainer initialized successfully")
        print(f"   - Device: {trainer.device}")
        print(f"   - Mixed precision: {trainer.use_amp}")
        print(f"   - Current curriculum ratio: {trainer.current_curriculum_ratio}")
        
    except Exception as e:
        if "CUDA" in str(e):
            print("‚ö†Ô∏è  Phase 3 trainer CUDA error (expected on non-GPU systems)")
            print("‚úÖ This will work correctly on Google Colab T4 GPU")
            print(f"   - Error: {e}")
        else:
            print(f"‚ùå Phase 3 trainer initialization error: {e}")
            traceback.print_exc()
            all_tests_passed = False
    
    # Test 5: Dataset loading
    print("\nüìä Test 5: Dataset Loading")
    try:
        from data import DatasetLoader
        
        data_loader = DatasetLoader(config_dict)
        train_datasets = data_loader.create_datasets('train')
        
        print("‚úÖ Dataset loading successful")
        for task_name, dataset in train_datasets.items():
            print(f"   - {task_name}: {len(dataset)} examples")
            
    except Exception as e:
        print(f"‚ùå Dataset loading error: {e}")
        all_tests_passed = False
    
    # Test 6: Loss function creation
    print("\nüéØ Test 6: Loss Function Creation")
    try:
        from training.losses import create_loss_function, CurriculumLoss
        
        # Create base loss function
        base_loss_fn = create_loss_function(
            config.training.__dict__,
            model.task_names,
            model.adapters.get_num_tasks()
        )
        
        # Create curriculum loss
        curriculum_schedule = {0: 0.5, 100: 0.7, 200: 0.9}
        curriculum_loss_fn = CurriculumLoss(base_loss_fn, curriculum_schedule)
        
        print("‚úÖ Loss functions created successfully")
        print(f"   - Base loss: {type(base_loss_fn).__name__}")
        print(f"   - Curriculum loss: {type(curriculum_loss_fn).__name__}")
        
    except Exception as e:
        print(f"‚ùå Loss function creation error: {e}")
        all_tests_passed = False
    
    # Test 7: Memory optimization settings
    print("\nüöÄ Test 7: Memory Optimization Settings")
    try:
        # Check environment variable
        pytorch_cuda_alloc = os.environ.get('PYTORCH_CUDA_ALLOC_CONF', '')
        
        # Check optimized config settings
        memory_settings = {
            'batch_size': getattr(config.training, 'batch_size', 'N/A'),
            'eval_batch_size': getattr(config.training, 'eval_batch_size', 'N/A'),
            'gradient_accumulation_steps': getattr(config.training, 'gradient_accumulation_steps', 'N/A'),
            'max_sequence_length': getattr(config.model, 'max_sequence_length', 'N/A'),
            'max_target_length': getattr(config.model, 'max_target_length', 'N/A'),
            'num_workers': getattr(config.data, 'num_workers', 'N/A'),
        }
        
        print("‚úÖ Memory optimization settings verified")
        for key, value in memory_settings.items():
            print(f"   - {key}: {value}")
            
        if 'expandable_segments:True' in pytorch_cuda_alloc:
            print("‚úÖ CUDA memory expansion enabled")
        else:
            print("‚ö†Ô∏è  CUDA memory expansion will be set at runtime")
            
    except Exception as e:
        print(f"‚ùå Memory optimization check error: {e}")
        all_tests_passed = False
    
    # Final summary
    print("\n" + "=" * 60)
    print("üìã PHASE 3 READINESS SUMMARY")
    print("=" * 60)
    
    if all_tests_passed:
        print("üéâ ALL TESTS PASSED!")
        print("‚úÖ Phase 3 is ready for Google Colab T4 GPU deployment")
        print("\nüöÄ To run Phase 3 on Google Colab:")
        print("   python train_optimized.py --phase 3 --no-resume")
        print("\nüìä Expected Phase 3 behavior:")
        print("   - Loads Phase 2 checkpoint (router + adapters)")
        print("   - Performs joint fine-tuning with curriculum learning")
        print("   - Memory optimized for T4 GPU (14.7GB)")
        print("   - Saves best joint model to checkpoints/phase3/")
        return True
    else:
        print("‚ùå SOME TESTS FAILED!")
        print("‚ö†Ô∏è  Please fix the issues above before deploying to GPU")
        return False

if __name__ == "__main__":
    success = test_phase3_readiness()
    exit(0 if success else 1) 